import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torch.distributions import Normal

class Actor(nn.Module):
    def __init__(self, self_state_dim: int, observe_state_dim: int, action_dim: int, 
                 hidden_dim: int, max_action: np.ndarray, device: torch.device):
        super(Actor, self).__init__()
        self.max_action = torch.FloatTensor(max_action)
        self.device = device
        self.action_dim = action_dim

        # RadarObserveTypeæœ‰6ç§ç±»å‹ï¼šUnfinishedGoal=0, Empty=1, FinishedGoal=2, Obstacle=3, Agent=4, Boundary=5
        self.num_radar_types = 6
        self.radar_type_embed_dim = 4  # embeddingç»´åº¦
        self.observe_state_dim = observe_state_dim
        
        # ä¸ºé›·è¾¾ç±»å‹åˆ›å»ºembeddingå±‚
        self.radar_type_embedding = nn.Embedding(self.num_radar_types, self.radar_type_embed_dim)
        
        # è¾“å…¥ç»´åº¦ï¼šself_state + observe_length + embedded_observe_type
        input_dim = self_state_dim + observe_state_dim + observe_state_dim * self.radar_type_embed_dim
        
        self.l1 = nn.Linear(input_dim, hidden_dim)
        self.l2 = nn.Linear(hidden_dim, hidden_dim)
        
        # MAPPOéœ€è¦è¾“å‡ºmeanå’Œlog_std
        self.mean_layer = nn.Linear(hidden_dim, action_dim)
        self.log_std_layer = nn.Linear(hidden_dim, action_dim)
        
        # Kaimingåˆå§‹åŒ–
        self._init_weights()
        
        self.to(device)
    
    def _init_weights(self):
        """Kaimingåˆå§‹åŒ–"""
        for layer in [self.l1, self.l2]:
            nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')
            nn.init.constant_(layer.bias, 0)
        
        # è¾“å‡ºå±‚ä½¿ç”¨è¾ƒå°çš„åˆå§‹åŒ–
        nn.init.uniform_(self.mean_layer.weight, -3e-3, 3e-3)
        nn.init.constant_(self.mean_layer.bias, 0)
        nn.init.uniform_(self.log_std_layer.weight, -3e-3, 3e-3)
        nn.init.constant_(self.log_std_layer.bias, -1.0)  # åˆå§‹åŒ–ä¸ºè¾ƒå°çš„æ ‡å‡†å·®
        
        # åˆå§‹åŒ–embeddingå±‚
        nn.init.xavier_uniform_(self.radar_type_embedding.weight)
    
    def forward(self, self_state: torch.Tensor, observe_length: torch.Tensor, observe_type: torch.Tensor):
        '''
        self_state: (batch_size, self_state_dim) æ™ºèƒ½ä½“è‡ªèº«çŠ¶æ€ x,y,theta
        observe_length: (batch_size, observe_state_dim) é›·è¾¾æ¢æµ‹åˆ°çš„éšœç¢ç‰©è·ç¦»
        observe_type: (batch_size, observe_state_dim) é›·è¾¾æ¢æµ‹åˆ°çš„éšœç¢ç‰©ç±»å‹
        '''
        self_state = self_state.to(self.device)
        observe_length = observe_length.to(self.device)
        observe_type = observe_type.to(self.device)
        
        # å°†observe_typeè½¬æ¢ä¸ºlongç±»å‹ç”¨äºembedding
        observe_type_long = observe_type.long()
        
        # é€šè¿‡embeddingå±‚å¤„ç†é›·è¾¾ç±»å‹
        embedded_observe_type = self.radar_type_embedding(observe_type_long)
        embedded_observe_type_flat = embedded_observe_type.view(embedded_observe_type.size(0), -1)
        
        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        x = torch.cat([self_state, observe_length, embedded_observe_type_flat], dim=1)    
        x = F.relu(self.l1(x))
        x = F.relu(self.l2(x))
        
        # è®¡ç®—meanå’Œlog_std
        mean = self.mean_layer(x)
        log_std = self.log_std_layer(x)
        
        # é™åˆ¶log_stdçš„èŒƒå›´ï¼Œé˜²æ­¢æ•°å€¼ä¸ç¨³å®š
        log_std = torch.clamp(log_std, min=-10, max=2)
        std = torch.exp(log_std)
        
        # ç¼©æ”¾åˆ°åŠ¨ä½œèŒƒå›´
        mean = torch.tanh(mean) * self.max_action.to(self.device)
        
        return mean, std
    
    def get_action_and_log_prob(self, self_state: torch.Tensor, observe_length: torch.Tensor, 
                               observe_type: torch.Tensor, deterministic: bool = False):
        """
        è·å–åŠ¨ä½œå’Œå¯¹æ•°æ¦‚ç‡ï¼Œç”¨äºè®­ç»ƒå’Œæ¨ç†
        """
        mean, std = self.forward(self_state, observe_length, observe_type)
        
        if deterministic:
            action = mean
            log_prob = None
        else:
            # åˆ›å»ºæ­£æ€åˆ†å¸ƒ
            dist = Normal(mean, std)
            # é‡‡æ ·åŠ¨ä½œ
            action = dist.sample()
            # è®¡ç®—å¯¹æ•°æ¦‚ç‡
            log_prob = dist.log_prob(action).sum(dim=-1, keepdim=True)
            
            # é™åˆ¶åŠ¨ä½œèŒƒå›´
            action = torch.clamp(action, -self.max_action.to(self.device), self.max_action.to(self.device))
        
        return action, log_prob
    
    def evaluate_actions(self, self_state: torch.Tensor, observe_length: torch.Tensor, 
                        observe_type: torch.Tensor, actions: torch.Tensor):
        """
        è¯„ä¼°ç»™å®šåŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡å’Œç†µï¼Œç”¨äºè®­ç»ƒæ—¶çš„ç­–ç•¥æ¢¯åº¦è®¡ç®—
        """
        mean, std = self.forward(self_state, observe_length, observe_type)
        
        # åˆ›å»ºæ­£æ€åˆ†å¸ƒ
        dist = Normal(mean, std)
        
        # è®¡ç®—å¯¹æ•°æ¦‚ç‡
        log_prob = dist.log_prob(actions).sum(dim=-1, keepdim=True)
        
        # è®¡ç®—ç†µ
        entropy = dist.entropy().sum(dim=-1, keepdim=True)
        
        return log_prob, entropy

class Critic(nn.Module):
    def __init__(self, all_state_dim: int, hidden_dim: int, device: torch.device):
        super(Critic, self).__init__()
        self.device = device

        # MAPPOçš„Criticåªéœ€è¦å…¨å±€çŠ¶æ€ï¼Œä¸éœ€è¦åŠ¨ä½œ
        self.l1 = nn.Linear(all_state_dim, hidden_dim)
        self.l2 = nn.Linear(hidden_dim, hidden_dim)
        self.l3 = nn.Linear(hidden_dim, hidden_dim)
        self.value_head = nn.Linear(hidden_dim, 1)
        
        # Kaimingåˆå§‹åŒ–
        self._init_weights()
        
        self.to(device)
    
    def _init_weights(self):
        """Kaimingåˆå§‹åŒ–"""
        for layer in [self.l1, self.l2, self.l3]:
            nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')
            nn.init.constant_(layer.bias, 0)
        # è¾“å‡ºå±‚ä½¿ç”¨è¾ƒå°çš„åˆå§‹åŒ–
        nn.init.uniform_(self.value_head.weight, -3e-3, 3e-3)
        nn.init.constant_(self.value_head.bias, 0)
    
    def forward(self, all_state: torch.Tensor) -> torch.Tensor:
        all_state = all_state.to(self.device)
        x = F.relu(self.l1(all_state))
        x = F.relu(self.l2(x))
        x = F.relu(self.l3(x))
        value = self.value_head(x)
        return value

def test_network():
    """
    æµ‹è¯•Actorå’ŒCriticç½‘ç»œçš„åŠŸèƒ½å’Œç»´åº¦
    """
    print("=" * 60)
    print("å¼€å§‹æµ‹è¯•MAPPOç½‘ç»œæ¨¡å—...")
    print("=" * 60)
    
    # è®¾ç½®æµ‹è¯•å‚æ•°
    num_agents = 2
    num_goals = 3
    num_obstacles = 5
    
    # ç½‘ç»œç»´åº¦å‚æ•°
    self_state_dim = 3  # x, y, theta
    observe_state_dim = 32  # é›·è¾¾æ¡æ•°
    action_dim = 2  # speed, angular_speed
    all_state_dim = num_agents * 3 + num_goals * 3 + num_obstacles * 3  # å…¨å±€çŠ¶æ€ç»´åº¦
    hidden_dim = 256
    max_action = np.array([1.0, 1.0])  # æœ€å¤§é€Ÿåº¦å’Œè§’é€Ÿåº¦
    batch_size = 5
    
    # è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    print(f"\næµ‹è¯•å‚æ•°:")
    print(f"  æ™ºèƒ½ä½“æ•°é‡: {num_agents}")
    print(f"  ç›®æ ‡æ•°é‡: {num_goals}")
    print(f"  éšœç¢ç‰©æ•°é‡: {num_obstacles}")
    print(f"  æ™ºèƒ½ä½“çŠ¶æ€ç»´åº¦: {self_state_dim}")
    print(f"  è§‚æµ‹ç»´åº¦: {observe_state_dim}")
    print(f"  åŠ¨ä½œç»´åº¦: {action_dim}")
    print(f"  å…¨å±€çŠ¶æ€ç»´åº¦: {all_state_dim}")
    print(f"  éšè—å±‚ç»´åº¦: {hidden_dim}")
    print(f"  æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"  æœ€å¤§åŠ¨ä½œ: {max_action}")
    
    try:
        # æµ‹è¯•Actorç½‘ç»œ
        print(f"\n{'='*30}")
        print("æµ‹è¯•Actorç½‘ç»œ...")
        print(f"{'='*30}")
        
        actor = Actor(self_state_dim, observe_state_dim, action_dim, hidden_dim, max_action, device)
        print(f"âœ“ Actorç½‘ç»œåˆ›å»ºæˆåŠŸ")
        print(f"  ç½‘ç»œå‚æ•°æ•°é‡: {sum(p.numel() for p in actor.parameters())}")
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        self_state = torch.randn(batch_size, self_state_dim)
        observe_length = torch.randn(batch_size, observe_state_dim)
        observe_type = torch.randint(0, 6, (batch_size, observe_state_dim)).float()
        
        print(f"\nè¾“å…¥ç»´åº¦:")
        print(f"  self_state: {self_state.shape}")
        print(f"  observe_length: {observe_length.shape}")
        print(f"  observe_type: {observe_type.shape}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        mean, std = actor(self_state, observe_length, observe_type)
        print(f"\nè¾“å‡ºç»´åº¦:")
        print(f"  mean: {mean.shape}")
        print(f"  std: {std.shape}")
        print(f"  æœŸæœ›ç»´åº¦: ({batch_size}, {action_dim})")
        
        # æµ‹è¯•åŠ¨ä½œé‡‡æ ·
        action, log_prob = actor.get_action_and_log_prob(self_state, observe_length, observe_type)
        print(f"\nåŠ¨ä½œé‡‡æ ·:")
        print(f"  action: {action.shape}")
        print(f"  log_prob: {log_prob.shape}")
        
        # æµ‹è¯•ç¡®å®šæ€§åŠ¨ä½œ
        det_action, _ = actor.get_action_and_log_prob(self_state, observe_length, observe_type, deterministic=True)
        print(f"  deterministic action: {det_action.shape}")
        
        # æµ‹è¯•åŠ¨ä½œè¯„ä¼°
        eval_log_prob, entropy = actor.evaluate_actions(self_state, observe_length, observe_type, action)
        print(f"\nåŠ¨ä½œè¯„ä¼°:")
        print(f"  eval_log_prob: {eval_log_prob.shape}")
        print(f"  entropy: {entropy.shape}")
        
        print(f"âœ“ Actorç½‘ç»œæµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•Criticç½‘ç»œ
        print(f"\n{'='*30}")
        print("æµ‹è¯•Criticç½‘ç»œ...")
        print(f"{'='*30}")
        
        critic = Critic(all_state_dim, hidden_dim, device)
        print(f"âœ“ Criticç½‘ç»œåˆ›å»ºæˆåŠŸ")
        print(f"  ç½‘ç»œå‚æ•°æ•°é‡: {sum(p.numel() for p in critic.parameters())}")
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        all_state = torch.randn(batch_size, all_state_dim)
        
        print(f"\nè¾“å…¥ç»´åº¦:")
        print(f"  all_state: {all_state.shape}")
        
        # å‰å‘ä¼ æ’­
        value = critic(all_state)
        print(f"\nè¾“å‡ºç»´åº¦:")
        print(f"  value: {value.shape}")
        print(f"  æœŸæœ›ç»´åº¦: ({batch_size}, 1)")
        
        print(f"\nä»·å€¼èŒƒå›´:")
        print(f"  ä»·å€¼æœ€å°å€¼: {value.min().item():.4f}")
        print(f"  ä»·å€¼æœ€å¤§å€¼: {value.max().item():.4f}")
        print(f"  ä»·å€¼å¹³å‡å€¼: {value.mean().item():.4f}")
        
        print(f"âœ“ Criticç½‘ç»œæµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•æ¢¯åº¦ä¼ æ’­
        print(f"\n{'='*30}")
        print("æµ‹è¯•æ¢¯åº¦ä¼ æ’­...")
        print(f"{'='*30}")
        
        # Actoræ¢¯åº¦æµ‹è¯•
        actor.zero_grad()
        action, log_prob = actor.get_action_and_log_prob(self_state, observe_length, observe_type)
        loss = log_prob.sum()
        loss.backward()
        
        actor_grad_norm = 0
        for param in actor.parameters():
            if param.grad is not None:
                actor_grad_norm += param.grad.data.norm(2).item() ** 2
        actor_grad_norm = actor_grad_norm ** 0.5
        
        print(f"Actoræ¢¯åº¦èŒƒæ•°: {actor_grad_norm:.6f}")
        assert actor_grad_norm > 0, "Actoræ¢¯åº¦ä¸ºé›¶"
        print(f"âœ“ Actoræ¢¯åº¦ä¼ æ’­æ­£å¸¸")
        
        # Criticæ¢¯åº¦æµ‹è¯•
        critic.zero_grad()
        value = critic(all_state)
        loss = value.sum()
        loss.backward()
        
        critic_grad_norm = 0
        for param in critic.parameters():
            if param.grad is not None:
                critic_grad_norm += param.grad.data.norm(2).item() ** 2
        critic_grad_norm = critic_grad_norm ** 0.5
        
        print(f"Criticæ¢¯åº¦èŒƒæ•°: {critic_grad_norm:.6f}")
        assert critic_grad_norm > 0, "Criticæ¢¯åº¦ä¸ºé›¶"
        print(f"âœ“ Criticæ¢¯åº¦ä¼ æ’­æ­£å¸¸")
        
        print(f"\n{'='*60}")
        print("ğŸ‰ æ‰€æœ‰MAPPOç½‘ç»œæµ‹è¯•é€šè¿‡ï¼")
        print("âœ“ Actorç½‘ç»œåŠŸèƒ½æ­£å¸¸ï¼ˆæ”¯æŒè¿ç»­åŠ¨ä½œç©ºé—´ï¼‰")
        print("âœ“ Criticç½‘ç»œåŠŸèƒ½æ­£å¸¸ï¼ˆåªéœ€è¦çŠ¶æ€è¾“å…¥ï¼‰") 
        print("âœ“ æ¢¯åº¦ä¼ æ’­æ­£å¸¸")
        print("âœ“ åŠ¨ä½œé‡‡æ ·å’Œè¯„ä¼°æ­£å¸¸")
        print("âœ“ ç»´åº¦åŒ¹é…æ­£ç¡®")
        print("âœ“ åŠ¨ä½œèŒƒå›´åˆç†")
        print(f"{'='*60}")
        
    except Exception as e:
        print(f"\nâŒ ç½‘ç»œæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise e

if __name__ == "__main__":
    test_network()
